@startmindmap
title =<i><b><u>Pooling [[../gif/pooling.adoc click gif]]

!theme hacker



*[#darkblue] <i>Pooling
**[#lightblue] <color #black><i><size:14>Definition
***[#green] <color #white><i><size:18>A technique in image processing, computer vision, and deep learning for reducing **"spatial dimensions"** while preserving <b>essential information.
***[#green] <color #white><i><size:18>Pooling is often applied after convolution to downsample feature maps.

**[#lightblue] <color #black><i><size:22>Pooling Types [[../gif/pooling-types.adoc click gif]]
***[#green] <b><color #white><i><size:14>Max Pooling
****[#yellow] <color #black><i><size:14>Retains the maximum value within a defined region and is suitable for detecting dominant features.
***[#green] <b><color #white><i><size:14>Average Pooling
****[#yellow] <color #black><i><size:14>Calculates the average value within a defined region, reducing sensitivity to noise.
***[#green] <b><color #white><i><size:14>Global Average Pooling
****[#yellow] <color #black><i><size:14>Computes the average value across the entire feature map, resulting in a global summary.
***[#green] <b><color #white><i><size:14>Min Pooling
****[#yellow] <color #black><i><size:14>Retains the minimum value within a defined region, useful for detecting darker areas.
***[#green] <b><color #white><i><size:14>Sum Pooling
****[#yellow] <color #black><i><size:14>Adds values within a defined region, preserving the total intensity.

**[#lightblue] <color #black><i><size:14>Pooling Parameters
***[#green] <b><color #white><i><size:14>Pooling Window Size
****[#yellow] <color #black><i><size:14>Defines the dimensions of the region over which pooling is performed (e.g., 2x2, 3x3).
***[#green] <b><color #white><i><size:14>Stride
****[#yellow] <color #black><i><size:14>Sets the step size at which the pooling window moves over the feature map.
***[#green] <b><color #white><i><size:14>Padding
****[#yellow] <color #black><i><size:14>Adding extra border pixels to maintain spatial dimensions during pooling.

**[#lightblue] <color #black><i><size:14>Pooling Purpose (advantages)
***[#green] <b><color #white><i><size:14>Dimension Reduction
****[#yellow] <color #black><i><size:14>Reduces the spatial dimensions of feature maps to save computational resources.
***[#green] <b><color #white><i><size:14>Translation Invariance
****[#yellow] *<color #black><i><size:14>Increases the model's tolerance to small spatial translations in data.\n* <color #black><i><size:14>**Recognizes features** regardless of **exact location.**\n<img:images/img_16.png>
***[#green] <b><color #white><i><size:14>Feature Highlighting
****[#yellow] <color #black><i><size:14>Focuses on essential features while discarding non-essential details.
***[#green] <b><color #white><i><size:14>Noise Robustness
****[#yellow] <color #black><i><size:14>Averages or selects extreme values, making features less sensitive to noise.

**[#lightblue] <color #black><i><size:14>Applications
***[#green] <b><color #white><i><size:14>Convolutional Neural Networks (CNNs)
****[#yellow] <color #black><i><size:14>Used in deep learning to downsample feature maps within the network.
***[#green] <b><color #white><i><size:14>Image Segmentation
****[#yellow] <color #black><i><size:14>Helps in partitioning images into regions and simplifying analysis.
***[#green] <b><color #white><i><size:14>Object Detection
****[#yellow] <color #black><i><size:14>Allows for detecting objects at different scales in an image.
***[#green] <b><color #white><i><size:14>Feature Selection
****[#yellow] <color #black><i><size:14>Aids in identifying the most significant features for a given task.

**[#lightblue] <color #black><i><size:14>Challenges
***[#green] <b><color #white><i><size:14>Information Loss
****[#yellow] <color #black><i><size:14>Pooling reduces spatial dimensions but may discard fine details.
***[#green] <b><color #white><i><size:14>Over-pooling
****[#yellow] <color #black><i><size:14>Excessive pooling can lead to significant information loss and reduced model performance.
***[#green] <b><color #white><i><size:14>Adaptive Pooling
****[#yellow] <color #black><i><size:14>Adapting pooling to the specifics of the data and task is a challenge.

**[#lightblue] <color #black><i><size:14>Pooling Strategies
***[#green] <b><color #white><i><size:14>Max Pooling and Average Pooling
****[#yellow] <color #black><i><size:14>Common strategies that balance between feature preservation and dimension reduction.
***[#green] <b><color #white><i><size:14>Adaptive Pooling
****[#yellow] <color #black><i><size:14>Learnable pooling techniques that adapt to data during training.
***[#green] <b><color #white><i><size:14>Global Pooling
****[#yellow] <color #black><i><size:14>Summarizes feature maps by considering global statistics.

**[#lightblue] <color #black><i><size:14>Trade-Offs
***[#green] <b><color #white><i><size:14>Stride vs. Overhead
****[#yellow] <color #black><i><size:14>Larger strides reduce dimensionality but can be computationally more expensive.
***[#green] <b><color #white><i><size:14>Pooling Size vs. Information Loss
****[#yellow] <color #black><i><size:14>Smaller pooling windows capture finer details but might lead to information loss.
***[#green] <b><color #white><i><size:14>Pooling vs. Striding
****[#yellow] <color #black><i><size:14>Striding can be an alternative to pooling for dimension reduction.

@endmindmap
