@startmindmap
title =Neural Network Architecture
skinparam node {
    BackgroundColor LightCyan
    BorderColor DarkBlue
}

* Neural Network Architecture
** Basics of Neural Networks
*** Neurons and Activation Functions - Neurons process input data and activation functions introduce non-linearity.
*** Weights and Biases - Neural networks learn by adjusting weights and biases in each layer.
*** Layers **(Input, Hidden, Output)** - Information flow through **layers (input, hidden, and output)** in a network.
*** Feedforward and Backpropagation - Feedforward for prediction and backpropagation for learning.

** Types of Neural Networks
***[#yellow] Feedforward Neural Networks **(FNN)** - Basic forward flow from input to output.
***[#yellow] Convolutional Neural Networks **(CNN)** - Specialized for image data with convolutional layers.
***[#yellow] Recurrent Neural Networks **(RNN)** - Process sequential data with loops.
***[#yellow] Long Short-Term Memory **(LSTM)** - Handles long-term dependencies in sequences.
***[#yellow] Gated Recurrent Units **(GRU)** - Simplified RNN with gating mechanisms.

** Layer Types
*** Input Layer - Receives and preprocesses input data.
***[#lime] ===Hidden Layers
****[#yellow] Fully Connected **(Dense)** Layers **- Each neuron connected to all neurons in the previous layer.**
****[#yellow] Convolutional Layers **- Detect patterns in input data using filters.**
****[#yellow] Recurrent Layers **- Process sequences and maintain hidden states.**
*** Output Layer - Produces the final network output.

** Activation Functions
*** Sigmoid **- Smoothly maps input to the range (0, 1).**
*** Hyperbolic Tangent (tanh) **- Maps input to the range (-1, 1).**
*** Rectified Linear Unit (ReLU) **- Commonly used, output is max(0, input).**
*** Leaky ReLU (LReLU) **- Avoids dead neurons by having a small slope for negative input.**
*** Exponential Linear Unit (ELU) **- Smoothly handles both positive and negative values.**

** Loss Functions
*** Mean Squared Error (MSE) - Measures the average squared difference between predicted and actual values.
*** Cross-Entropy Loss - Measures the dissimilarity between predicted and actual distributions.
*** Hinge Loss - Used in support vector machines and ranking problems.
*** Huber Loss - A combination of MSE and absolute error loss.
*** Custom Loss Functions - Tailored for specific tasks or objectives.

** Optimizers
*** Gradient Descent - Updates weights based on the gradient of the loss.
*** Stochastic Gradient Descent (SGD) - Uses random samples for faster convergence.
*** Adam Optimizer - Adaptive optimization with momentum.
*** RMSprop - Root Mean Square Propagation for adjusting learning rates.
*** Adagrad - Adaptive learning rates for sparse data.

** Regularization
*** L1 Regularization (Lasso) - Encourages sparsity in weights.
*** L2 Regularization (Ridge) - Prevents large weight values.
*** Dropout - Randomly deactivates neurons during training.
*** Batch Normalization - Normalizes activations in mini-batches.
*** Weight Decay - Penalizes large weight values.

** Training and Validation
*** Training Data and Batches - Data used for training and splitting it into batches.
*** Learning Rate - Controls the step size in weight updates.
*** Early Stopping - Prevents overfitting by stopping training when validation error increases.
*** Overfitting and Underfitting - Challenges in finding the right model complexity.
*** Validation and Testing - Crucial for assessing model performance.

** Applications
*** Image Classification - Identifying objects or patterns in images.
*** Natural Language Processing (NLP) - Processing and understanding text data.
*** Speech Recognition - Converting spoken language into text.
*** Computer Vision - Analyzing visual data from images and videos.
*** Autonomous Vehicles - Enabling self-driving cars and robotics.

** Frameworks and Libraries
*** TensorFlow - Developed by Google, open-source, and versatile.
*** PyTorch - Open-source platform for research and development.
*** Keras - High-level neural network API for rapid prototyping.
*** scikit-learn - Machine learning library for Python.
*** Caffe - Deep learning framework for vision tasks.

** Challenges and Advanced Concepts
*** Vanishing and Exploding Gradients - Issues in gradient flow during training.
*** Gradient Clipping - Technique to mitigate gradient issues.
*** Transfer Learning - Leveraging pre-trained models for new tasks.
*** Generative Adversarial Networks (GANs) - Models for generating data.
*** Reinforcement Learning with Neural Networks - Integrating neural networks into reinforcement learning.

** Interdisciplinary Fields
*** Artificial Intelligence (AI) - Neural networks play a central role in AI.
*** Machine Learning (ML) - A subset of AI heavily reliant on neural networks.
*** Deep Learning - A subfield of ML focused on neural networks.
*** Cognitive Computing - Emulates human-like thinking and reasoning.
*** Neural Network Hardware - Specialized hardware for efficient neural network execution.

** Ethical and Legal Considerations
*** Bias and Fairness - Addressing biases in training data and models.
*** Privacy Concerns - Protecting sensitive data in AI applications.
*** Regulatory Compliance - Adhering to legal and ethical standards.
*** Responsible AI - Ensuring AI systems make ethical decisions.

** Future Developments
*** Architectural Innovations - Ongoing advancements in neural network design.
*** Explainable AI (XAI) - Making AI decision-making more transparent.
*** Human-Machine Collaboration - Synergy between AI and human intelligence.
*** Integration with IoT - Neural networks in the Internet of Things.
*** Quantum Computing and Neural Networks - Potential synergy between quantum computing and deep learning.

** Research Areas and Unsolved Problems
*** Explainability in Deep Learning - Making neural network decisions understandable.
*** Compositional and Symbolic Reasoning - Enhancing AI's reasoning capabilities.
*** AI Safety and Robustness - Ensuring AI systems are safe and reliable.
*** Generalization in Neural Networks - Understanding and improving generalization.
*** Conscious AI and Cognitive Science - Exploring AI with human-like cognitive abilities.
@endmindmap
